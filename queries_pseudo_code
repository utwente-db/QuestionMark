This file contains the pseudo-code that forms the basis of the benchmark queries.
In this program, this pseudo-code can be found translated to the SQL dialects of MayBMS and DuBio.

Please go to 'queries-dubio' to see how this pseudo-code translates to the dialect of DuBio.
Please go to 'queries-maybms' to see how this pseudo-code translates to the dialect of MayBMS.

Explain Analyse only works with the following statements:
SELECT, INSERT, UPDATE, DELETE, VALUES, EXECUTE, DECLARE, CREATE TABLE AS, or CREATE MATERIALIZED VIEW AS.
The use of any other statement will throw an error. Be wary of this when adding queries to this benchmark.

The queries are divided into the following categories:
    - basic queries
    - probability centered queries
    - conditional queries
    - aggregation queries
    - evidence addition
    - insert, update, delete   # Now assuming random delete isn't much slower than deleting last x.


Comments about the use of the queries:
# TODO: Add the queries.

test_1:       Simple query to test the connection.

basic_1:      Provides insight into the dataset.
basic_2:      Provides insight into the distribution of cluster volumes.

condition_1:  Returns all clusters that contain a product with 'ford'.

insert_1:     Inserts new offers into the database.
insert_2:     Inserts the new sentences into the database.
update_1:     Changes a selection of offers.
update_2:     Adds new evidence to the database.
delete_1:     Deletes a selection of offers from the database.

For the insert queries, the data file 'insert_offers.sql' and 'insert_dict.sql' will be run.
    These files are created by running the functions in insert_query.py in the prob-matcher program.


# ====== TEST THE CONNECTION ==================================================================== #

# == QUERY TEST 1 == #
select all attributes
from entity 'offers'
return the first 10 records;


# ====== BASIC QUERIES ========================================================================== #

# == QUERY BASIC 1 == #
select the count of records alias 'records', the count of distinct 'id' attribute values alias 'offers',
    and the count of distinct 'cluster_id' attribute values alias 'clusters'
from entity 'offers';

# == QUERY BASIC 2 == #
select 'cluster_size', the count of 'cluster_size' values alias 'amount'
from (
    select the count of distinct 'id' attribute values alias 'cluster_size'
    from entity 'offers'
    group by 'cluster_id'
) alias 'cluster_sizes'
group by 'cluster_size'
order by 'cluster_size' ascending;


# ====== PROBABILITY CENTERED QUERIES =========================================================== #

# ====== CONDITIONAL QUERIES ==================================================================== #

# TODO: preparation and analysis

# == QUERY CONDITION 1 == #
select all attributes
from entity 'offers'
where attribute 'name' contains "ford"
and attribute 'description' contains "ford"
and attribute 'brand' contains "ford"
order by 'cluster_id' ascending;

# ====== AGGREGATE QUERIES ====================================================================== #

# ====== EVIDENCE ADDITION ====================================================================== #

# ====== INSERT, UPDATE, DELETE ================================================================= #

# == QUERY INSERT 1 == #

# == QUERY INSERT 2 == #

# == QUERY UPDATE 1 == #

# == QUERY UPDATE 2 == #

# == QUERY DELETE 1 == #




